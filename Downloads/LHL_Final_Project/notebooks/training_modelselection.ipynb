{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (512887, 18)\n",
      "X_test shape: (128222, 18)\n",
      "y_train shape: (512887,)\n",
      "y_test shape: (128222,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "# Load the balanced data\n",
    "\n",
    "balanced_data = pd.read_csv('csvs/balanced_data.csv')\n",
    "\n",
    "# Separate features and target variable\n",
    "\n",
    "X = balanced_data.drop(columns=['Diabetes_012'])\n",
    "y = balanced_data['Diabetes_012']\n",
    "\n",
    "# Split the data into training (80%) and test (20%) sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'y_test' (Series)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_test' (Series)\n",
      "Stored 'X' (DataFrame)\n",
      "Stored 'y' (Series)\n"
     ]
    }
   ],
   "source": [
    "# Will need these later!\n",
    "\n",
    "%store X_train\n",
    "%store y_test\n",
    "%store X_test\n",
    "%store y_test\n",
    "%store X\n",
    "%store y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets use 5 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Train: 410309\n",
      "  Validation: 102578\n",
      "Fold 2:\n",
      "  Train: 410309\n",
      "  Validation: 102578\n",
      "Fold 3:\n",
      "  Train: 410310\n",
      "  Validation: 102577\n",
      "Fold 4:\n",
      "  Train: 410310\n",
      "  Validation: 102577\n",
      "Fold 5:\n",
      "  Train: 410310\n",
      "  Validation: 102577\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation with 5 folds\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Display the indices for each fold\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X_train)):\n",
    "    print(f\"Fold {fold + 1}:\")\n",
    "    print(f\"  Train: {len(train_index)}\")\n",
    "    print(f\"  Validation: {len(val_index)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that that is done, its time to select a model. Since we are talking about diabetes or not, this is a classification problem. Ill start with logistic regression as a baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model - Logistic Regression:\n",
      "  Accuracy: 0.5341\n",
      "  F1 Score: 0.5282\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "\n",
    "baseline_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "\n",
    "y_pred = baseline_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Baseline Model - Logistic Regression:\")\n",
    "print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "print(f\"  F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, lets move onto model selection and hypertuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ill train these models and use cross-validation to evaluate their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree F1 Score: 0.6407 (+/- 0.0018)\n",
      "Random Forest F1 Score: 0.7399 (+/- 0.0016)\n",
      "SVM F1 Score: 0.5342 (+/- 0.0025)\n",
      "XGBoost F1 Score: 0.7376 (+/- 0.0043)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Load the balanced dataset\n",
    "\n",
    "balanced_data = pd.read_csv('csvs/balanced_data.csv')\n",
    "\n",
    "# Split data into features and target\n",
    "\n",
    "X = balanced_data.drop(columns='Diabetes_012')\n",
    "y = balanced_data['Diabetes_012']\n",
    "\n",
    "# Use smaller subset of the data\n",
    "\n",
    "X_subset, _, y_subset, _ = train_test_split(X, y, train_size=0.05, stratify=y, random_state=42)\n",
    "\n",
    "# Define models with reduced complexity (faster times)\n",
    "\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=50, random_state=42),  # reduced number of trees\n",
    "    \"SVM\": SVC(random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=50, random_state=42)  # reduced number of trees\n",
    "}\n",
    "\n",
    "# Evaluate models using fewer cross-validation folds\n",
    "\n",
    "def evaluate_models(models, X_train, y_train, cv=3):\n",
    "    results = {}\n",
    "    for model_name, model in models.items():\n",
    "        scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='f1_macro')\n",
    "        results[model_name] = scores\n",
    "        print(f\"{model_name} F1 Score: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n",
    "    return results\n",
    "\n",
    "# Evaluate models\n",
    "\n",
    "results = evaluate_models(models, X_subset, y_subset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'X_subset' (DataFrame)\n",
      "Stored 'y_subset' (Series)\n"
     ]
    }
   ],
   "source": [
    "# To use in next notebook\n",
    "\n",
    "%store X_subset\n",
    "%store y_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest model has the highest f1 score. it is the best preformance among the models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
